{"cells":[{"cell_type":"markdown","metadata":{"id":"tadmzyfzzcHX"},"source":["# Variational AutoEncoder\n","\n","**Author:** [fchollet](https://twitter.com/fchollet)<br>\n","**Date created:** 2020/05/03<br>\n","**Last modified:** 2020/05/03<br>\n","**Description:** Convolutional Variational AutoEncoder (VAE) trained on MNIST digits."]},{"cell_type":"markdown","metadata":{"id":"O4XreA4HzcHd"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EuoQ7VLnzcHd"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","metadata":{"id":"6B5waOm9zcHf"},"source":["## Create a sampling layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2MgBA3rzcHf"},"outputs":[],"source":["\n","class Sampling(layers.Layer):\n","    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"]},{"cell_type":"markdown","metadata":{"id":"9BFf6wJTzcHg"},"source":["## Build the encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vp5CZ-_CzcHh","executionInfo":{"status":"ok","timestamp":1663962301123,"user_tz":180,"elapsed":39,"user":{"displayName":"","userId":""}},"outputId":"b4afc8b4-22ef-4527-b4e2-047614993151","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 14, 14, 32)   320         ['input_1[0][0]']                \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d[0][0]']                 \n","                                                                                                  \n"," flatten (Flatten)              (None, 3136)         0           ['conv2d_1[0][0]']               \n","                                                                                                  \n"," dense (Dense)                  (None, 16)           50192       ['flatten[0][0]']                \n","                                                                                                  \n"," z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n","                                                                                                  \n"," z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n","                                                                                                  \n"," sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 69,076\n","Trainable params: 69,076\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["latent_dim = 2\n","\n","encoder_inputs = keras.Input(shape=(28, 28, 1))\n","x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n","x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(16, activation=\"relu\")(x)\n","z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n","z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n","z = Sampling()([z_mean, z_log_var])\n","encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n","encoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"474EMy4CzcHi"},"source":["## Build the decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk81peO7zcHi","executionInfo":{"status":"ok","timestamp":1663962301123,"user_tz":180,"elapsed":23,"user":{"displayName":"","userId":""}},"outputId":"02099874-7fa4-4112-8e2e-726b516cb708","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 2)]               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 3136)              9408      \n","                                                                 \n"," reshape (Reshape)           (None, 7, 7, 64)          0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n"," nspose)                                                         \n","                                                                 \n"," conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n"," ranspose)                                                       \n","                                                                 \n"," conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 65,089\n","Trainable params: 65,089\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["latent_inputs = keras.Input(shape=(latent_dim,))\n","x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n","x = layers.Reshape((7, 7, 64))(x)\n","x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n","decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n","decoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"c6MGaHXEzcHj"},"source":["## Define the VAE as a `Model` with a custom `train_step`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"na9rRpzJzcHk"},"outputs":[],"source":["\n","class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss\"\n","        )\n","        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            reconstruction_loss = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n","                )\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"1dueaQVLzcHl"},"source":["## Train the VAE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKs8EhpBzcHl"},"outputs":[],"source":["(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","mnist_digits = np.concatenate([x_train, x_test], axis=0)\n","mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n","\n","vae = VAE(encoder, decoder)\n","vae.compile(optimizer=keras.optimizers.Adam())\n","vae.fit(mnist_digits, epochs=30, batch_size=128)"]},{"cell_type":"markdown","metadata":{"id":"tqhvKyIZzcHl"},"source":["## Display a grid of sampled digits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RjnLETRSzcHm"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_latent_space(vae, n=30, figsize=15):\n","    # display a n*n 2D manifold of digits\n","    digit_size = 28\n","    scale = 1.0\n","    figure = np.zeros((digit_size * n, digit_size * n))\n","    # linearly spaced coordinates corresponding to the 2D plot\n","    # of digit classes in the latent space\n","    grid_x = np.linspace(-scale, scale, n)\n","    grid_y = np.linspace(-scale, scale, n)[::-1]\n","\n","    for i, yi in enumerate(grid_y):\n","        for j, xi in enumerate(grid_x):\n","            z_sample = np.array([[xi, yi]])\n","            x_decoded = vae.decoder.predict(z_sample)\n","            digit = x_decoded[0].reshape(digit_size, digit_size)\n","            figure[\n","                i * digit_size : (i + 1) * digit_size,\n","                j * digit_size : (j + 1) * digit_size,\n","            ] = digit\n","\n","    plt.figure(figsize=(figsize, figsize))\n","    start_range = digit_size // 2\n","    end_range = n * digit_size + start_range\n","    pixel_range = np.arange(start_range, end_range, digit_size)\n","    sample_range_x = np.round(grid_x, 1)\n","    sample_range_y = np.round(grid_y, 1)\n","    plt.xticks(pixel_range, sample_range_x)\n","    plt.yticks(pixel_range, sample_range_y)\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.imshow(figure, cmap=\"Greys_r\")\n","    plt.show()\n","\n","\n","plot_latent_space(vae)"]},{"cell_type":"markdown","metadata":{"id":"XxNiP-bXzcHn"},"source":["## Display how the latent space clusters different digit classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X81RyBl3zcHn","executionInfo":{"status":"error","timestamp":1665449576437,"user_tz":180,"elapsed":5,"user":{"displayName":"Alex Rios","userId":"06815287992103896260"}},"outputId":"8888ab77-d1a0-4d52-d300-a03861348649","colab":{"base_uri":"https://localhost:8080/","height":236}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7a597a1a0c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"]}],"source":["\n","def plot_label_clusters(vae, data, labels):\n","    # display a 2D plot of the digit classes in the latent space\n","    z_mean, _, _ = vae.encoder.predict(data)\n","    plt.figure(figsize=(12, 10))\n","    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n","    plt.colorbar()\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.show()\n","\n","\n","(x_train, y_train), _ = keras.datasets.mnist.load_data()\n","x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n","\n","plot_label_clusters(vae, x_train, y_train)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb","timestamp":1663962415932}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}